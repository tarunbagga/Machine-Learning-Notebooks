{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Baseline1.ipynb","provenance":[{"file_id":"1oPtjpThhRk-PwKTSbxjVq_Wx-HXh6Sd7","timestamp":1593883887468},{"file_id":"17QiH3zP5I2YvjPEoOmVPcVWXbEAZJivw","timestamp":1593230578703}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WWaZkYetFF50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594564265672,"user_tz":240,"elapsed":45479,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}},"outputId":"19ed3a72-e3ee-4184-c0dd-dbc186d6342b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WUq_GOJMFHZs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564265674,"user_tz":240,"elapsed":45477,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["test_path = 'gdrive/My Drive/chest_xray/test'  #change dir to your project folder"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzQYyccmF0zh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564265675,"user_tz":240,"elapsed":45475,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["train_path = 'gdrive/My Drive/chest_xray/train'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gu0ncJ4JFUj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1594564265676,"user_tz":240,"elapsed":45450,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}},"outputId":"b090f885-6191-408d-9112-eded442e0f83"},"source":["import os\n","os.listdir('/')"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['dev',\n"," 'root',\n"," 'lib',\n"," 'tmp',\n"," 'mnt',\n"," 'sbin',\n"," 'srv',\n"," 'opt',\n"," 'media',\n"," 'proc',\n"," 'usr',\n"," 'boot',\n"," 'var',\n"," 'home',\n"," 'lib64',\n"," 'sys',\n"," 'bin',\n"," 'etc',\n"," 'run',\n"," 'content',\n"," '.dockerenv',\n"," 'tools',\n"," 'datalab',\n"," 'swift',\n"," 'dlib-19.18.0-cp27-cp27mu-linux_x86_64.whl',\n"," 'tensorflow-1.15.2',\n"," 'dlib-19.18.0-cp36-cp36m-linux_x86_64.whl',\n"," 'lib32']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Os33BYoqF5gZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594564269327,"user_tz":240,"elapsed":49098,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}},"outputId":"73bcd597-4e55-44e5-d21a-8c0c73ddcf19"},"source":["## Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","#print(os.listdir(\"../input\"))\n","\n","import random\n","import warnings\n","from sklearn.metrics import confusion_matrix\n","warnings.filterwarnings('ignore')\n","\n","#File Operation libraries\n","import glob\n","from pathlib import Path\n","\n","#Visualisation Libraries\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from mlxtend.plotting import plot_confusion_matrix\n","\n","#Keras\n","from keras.layers import Dense, Conv2D, MaxPooling2D, AvgPool2D, Input, Dropout, Flatten, BatchNormalization\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg19 import VGG19\n","\n","#Image Transformation Libraries\n","import cv2\n","from imgaug import augmenters as iaa\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","#print(os.listdir(\"../input\"))\n","\n","from os import listdir, makedirs\n","from os.path import join, exists, expanduser\n","\n","from keras import applications\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras import backend as K\n","import tensorflow as tf\n","from keras.utils.data_utils import Sequence\n","import sys\n","from PIL import *\n","sys.modules['Image'] = Image \n","# Any results you write to the current directory are saved as output.\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ttHcwU244o7J","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564269329,"user_tz":240,"elapsed":49097,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["# General libraries\n","import os\n","import numpy as np\n","import pandas as pd \n","import random\n","import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Deep learning libraries\n","import keras.backend as K\n","from keras.models import Model, Sequential\n","from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n","from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","import tensorflow as tf\n","\n","# Setting seeds for reproducibility\n","seed = 232\n","np.random.seed(seed)\n","#tf.set_random_seed(seed)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"gz0lD2_NJgqw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564269330,"user_tz":240,"elapsed":49095,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["base_dir='gdrive/My Drive/chest_xray'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"GIIiOnxcI7AM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564269332,"user_tz":240,"elapsed":49094,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["train_data = base_dir+'/train/'\n","test_data = base_dir+'/test/'\n","val_data = base_dir+'/val/'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjeHB9VvZyYM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594564269333,"user_tz":240,"elapsed":49069,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}},"outputId":"72e5242c-65e7-4bc1-d0ab-c5f40066991d"},"source":["train_data"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'gdrive/My Drive/chest_xray/train/'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"zoEFykV1tYW1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594564269334,"user_tz":240,"elapsed":49055,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}},"outputId":"71e2faf3-f0a8-4e6b-e0e7-6c9d81907a4d"},"source":["\n","base_dir "],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'gdrive/My Drive/chest_xray'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Imcb6Q0qiRZa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564269334,"user_tz":240,"elapsed":49049,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["image_size = (180, 180)\n","batch_size = 32"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYUlK2vg6xYY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564269335,"user_tz":240,"elapsed":49046,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["# input_path = '../input/chest_xray/chest_xray/'\n","input_path = base_dir + '/'\n","\n","def process_data(img_dims, batch_size):\n","    # Data generation objects\n","    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n","    test_val_datagen = ImageDataGenerator(rescale=1./255)\n","    \n","    # This is fed to the network in the specified batch sizes and image dimensions\n","    train_gen = train_datagen.flow_from_directory(\n","    directory=input_path+'train', \n","    target_size=(img_dims, img_dims), \n","    batch_size=batch_size, \n","    class_mode='binary', \n","    shuffle=True)\n","\n","    test_gen = test_val_datagen.flow_from_directory(\n","    directory=input_path+'test', \n","    target_size=(img_dims, img_dims), \n","    batch_size=batch_size, \n","    class_mode='binary', \n","    shuffle=True)\n","    \n","    # I will be making predictions off of the test set in one batch size\n","    # This is useful to be able to get the confusion matrix\n","    test_data = []\n","    test_labels = []\n","\n","    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n","        for img in (os.listdir(input_path + 'test' + cond)):\n","            img = plt.imread(input_path+'test'+cond+img)\n","            img = cv2.resize(img, (img_dims, img_dims))\n","            img = np.dstack([img, img, img])\n","            img = img.astype('float32') / 255\n","            if cond=='/NORMAL/':\n","                label = 0\n","            elif cond=='/PNEUMONIA/':\n","                label = 1\n","            test_data.append(img)\n","            test_labels.append(label)\n","        \n","    test_data = np.array(test_data)\n","    test_labels = np.array(test_labels)\n","    \n","    return train_gen, test_gen, test_data, test_labels"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"kHmVlYqb67CA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594564662239,"user_tz":240,"elapsed":441926,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}},"outputId":"2fafc86b-58df-4511-e076-2455d4de7bc1"},"source":["# Hyperparameters\n","img_dims = 150\n","epochs = 30\n","batch_size = 48\n","\n","# Getting the data\n","train_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Found 5218 images belonging to 2 classes.\n","Found 631 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f1X4xgrq7jcO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594564670042,"user_tz":240,"elapsed":449726,"user":{"displayName":"Tarun Bagga","photoUrl":"","userId":"01048250861716837911"}}},"source":["\n","# Input layer\n","inputs = Input(shape=(img_dims, img_dims, 3))\n","\n","# First conv block\n","x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n","x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = MaxPool2D(pool_size=(2, 2))(x)\n","\n","# Second conv block\n","x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPool2D(pool_size=(2, 2))(x)\n","\n","# Third conv block\n","x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPool2D(pool_size=(2, 2))(x)\n","\n","# Fourth conv block\n","x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPool2D(pool_size=(2, 2))(x)\n","x = Dropout(rate=0.2)(x)\n","\n","# Fifth conv block\n","x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPool2D(pool_size=(2, 2))(x)\n","x = Dropout(rate=0.2)(x)\n","\n","# FC layer\n","x = Flatten()(x)\n","x = Dense(units=512, activation='relu')(x)\n","x = Dropout(rate=0.7)(x)\n","x = Dense(units=128, activation='relu')(x)\n","x = Dropout(rate=0.5)(x)\n","x = Dense(units=64, activation='relu')(x)\n","x = Dropout(rate=0.3)(x)\n","\n","# Output layer\n","output = Dense(units=1, activation='sigmoid')(x)\n","\n","# Creating model and compiling\n","model = Model(inputs=inputs, outputs=output)\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Callbacks\n","checkpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\n","lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n","early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yEQYEh69IA9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"07ae83ad-d305-4ee8-fdd1-f2553ef59628"},"source":["# Fitting the model\n","hist = model.fit_generator(\n","           train_gen, steps_per_epoch=train_gen.samples // batch_size, \n","           epochs=epochs, validation_data=test_gen, \n","           validation_steps=test_gen.samples // batch_size, callbacks=[checkpoint, lr_reduce])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","  4/108 [>.............................] - ETA: 51:26 - loss: 0.6837 - accuracy: 0.6719"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SLfU15Ek9SWL","colab_type":"code","colab":{}},"source":["fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n","ax = ax.ravel()\n","\n","for i, met in enumerate(['acc', 'loss']):\n","    ax[i].plot(hist.history[met])\n","    ax[i].plot(hist.history['val_' + met])\n","    ax[i].set_title('Model {}'.format(met))\n","    ax[i].set_xlabel('epochs')\n","    ax[i].set_ylabel(met)\n","    ax[i].legend(['train', 'val'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h6zOBlZciX_t","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","data_augmentation = tf.keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(0.1),\n","    ]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjPZfRuP82DY","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255)\n","val_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data,\n","    target_size=(180, 180),\n","    batch_size=32,\n","    class_mode='categorical')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_data,\n","    target_size=(180, 180),\n","    batch_size=32,\n","    class_mode='categorical')\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    val_data,\n","    target_size=(180, 180),\n","    batch_size=32,\n","    class_mode='categorical')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHmWa3fOjfKV","colab_type":"code","colab":{}},"source":["def make_model(input_shape, num_classes):\n","    inputs = keras.Input(shape=input_shape)\n","    # Image augmentation block\n","    x = data_augmentation(inputs)\n","\n","    # Entry block\n","    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n","    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    previous_block_activation = x  # Set aside residual\n","\n","    for size in [128, 256, 512, 728]:\n","        x = layers.Activation(\"relu\")(x)\n","        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","        x = layers.BatchNormalization()(x)\n","\n","        x = layers.Activation(\"relu\")(x)\n","        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","        x = layers.BatchNormalization()(x)\n","\n","        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","        # Project residual\n","        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n","            previous_block_activation\n","        )\n","        x = layers.add([x, residual])  # Add back residual\n","        previous_block_activation = x  # Set aside next residual\n","\n","    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","    if num_classes == 2:\n","        activation = \"sigmoid\"\n","        units = 1\n","    else:\n","        activation = \"softmax\"\n","        units = num_classes\n","\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(units, activation=activation)(x)\n","    return keras.Model(inputs, outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ad_eU2CijrAg","colab_type":"code","colab":{}},"source":["model = make_model(input_shape=image_size + (3,), num_classes=2)\n","keras.utils.plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwZteuCokTjh","colab_type":"code","colab":{}},"source":["epochs = 5\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n","]\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-3),\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","model.fit(\n","    train_generator, epochs=epochs, callbacks=callbacks, validation_data=test_generator,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2GAM1UEko4K","colab_type":"code","colab":{}},"source":["img = keras.preprocessing.image.load_img(\n","    base_dir + \"/test/PNEUMONIA/person1_virus_7.jpeg\", target_size=image_size\n",")\n","img_array = keras.preprocessing.image.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n","\n","predictions = model.predict(img_array)\n","score = predictions[0]\n","print(score)\n","print(\n","    \"This image is %.2f percent NORMAL and %.2f percent PNEUMONIA.\"\n","    % (100 * (1 - score), 100 * score)\n",")\n"],"execution_count":null,"outputs":[]}]}